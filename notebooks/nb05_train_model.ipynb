{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report,confusion_matrix\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data_preprocss/data_onevisa_postprocess_v2.csv')#.set_index('sample_id')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col='type_case'\n",
    "\n",
    "X = df.drop(columns=[target_col]+['sample_id'])\n",
    "y = df[target_col].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cat_placeholder = 'nan'\n",
    "\n",
    "for c in cat_cols:\n",
    "    X[c] = X[c].astype(str).fillna(missing_cat_placeholder)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "train_pool = Pool(data=X_train, label=y_train, cat_features=cat_cols)\n",
    "test_pool = Pool(data=X_test, label=y_test, cat_features=cat_cols)\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "        iterations=300,\n",
    "        learning_rate=0.01,\n",
    "        depth=6,\n",
    "        eval_metric='Recall',\n",
    "        random_seed=42,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "# Fit the model\n",
    "model.fit(train_pool, eval_set=test_pool)\n",
    "    \n",
    "# Predictions\n",
    "y_pred = model.predict(test_pool)\n",
    "y_pred_prob = model.predict_proba(test_pool)\n",
    "\n",
    "    \n",
    "# Compute metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, pos_label='granted', zero_division=0)\n",
    "rec = recall_score(y_test, y_pred, pos_label='granted', zero_division=0)\n",
    "    \n",
    "print(f\"Accuracy:  {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall:    {rec:.3f}\")\n",
    "print(\"\\nFull classification report:\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame()\n",
    "df_pred['preds'] = y_pred\n",
    "df_pred['preds_prob1'] = y_pred_prob[:,1]\n",
    "df_pred['preds_prob0'] = y_pred_prob[:,0]\n",
    "\n",
    "\n",
    "df_pred['gt_values'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.gt_values.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Refused',df_pred[df_pred.gt_values=='refused'].preds_prob1.median())\n",
    "print('Granted',df_pred[df_pred.gt_values=='refused'].preds_prob0.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Refused',df_pred[df_pred.gt_values=='granted'].preds_prob1.median())\n",
    "print('Granted',df_pred[df_pred.gt_values=='granted'].preds_prob0.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_truc = np.where(y_pred_prob[:,1] > 0.3, 'refused', 'granted')\n",
    "#pred_truc = np.where(y_pred_prob[:,0] > 0.9, 'granted', 'refused')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, pred_truc)\n",
    "prec = precision_score(y_test, pred_truc, pos_label='granted', zero_division=0)\n",
    "rec = recall_score(y_test, pred_truc, pos_label='granted', zero_division=0)\n",
    "    \n",
    "print(f\"Accuracy:  {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall:    {rec:.3f}\")\n",
    "print(\"\\nFull classification report:\\n\")\n",
    "print(classification_report(y_test, pred_truc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['granted', 'refused']  # adjust order if needed\n",
    "\n",
    "# 1) compute raw matrix\n",
    "cm = confusion_matrix(y_test, pred_truc, labels=labels)\n",
    "\n",
    "# 2) wrap in a DataFrame for clarity\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[f\"actual_{lab}\"   for lab in labels],\n",
    "    columns=[f\"predicted_{lab}\" for lab in labels]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_training import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_columns_with_mixed_dtypes(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Prints columns in the DataFrame that contain mixed data types (e.g., strings and numbers).\n",
    "    \"\"\"\n",
    "    mixed_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        types_in_col = set(type(val) for val in df[col].dropna())\n",
    "        if len(types_in_col) > 1:\n",
    "            mixed_cols.append((col, types_in_col))\n",
    "\n",
    "    if mixed_cols:\n",
    "        print(\"Columns with mixed data types:\")\n",
    "        for col, types_found in mixed_cols:\n",
    "            print(f\"  - {col}: {types_found}\")\n",
    "    else:\n",
    "        print(\"No columns with mixed data types found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_columns_with_mixed_dtypes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postal_code = [i for i in df.columns if 'postal' in i]\n",
    "mobile_phone = [i for i in df.columns if 'phone' in i]\n",
    "df = df.drop(columns = postal_code + mobile_phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_columns_with_mixed_dtypes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb, df_pred_xgb = train_model(df, model_type ='xgboost',\n",
    "                                     target_col='type_case', threshold=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
