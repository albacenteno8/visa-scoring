{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report,confusion_matrix\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f0/dt7lkxv100q68c369j1bzgk00000gn/T/ipykernel_1217/3626837.py:1: DtypeWarning: Columns (143,188,214,233,262,263,264,290,293,294,295,298,299,300,301,302,303,305,306,307,308,309,310,311,312,314,315,318,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,362,364,368,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,388,389,393,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,436,437,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,514,515) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data_preprocss/data_onevisa_postprocess_v2.csv')#.set_index('sample_id')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5340, 538)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data_preprocss/data_onevisa_postprocess_v2.csv')#.set_index('sample_id')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col='type_case'\n",
    "\n",
    "X = df.drop(columns=[target_col]+['sample_id'])\n",
    "y = df[target_col].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 109ms\tremaining: 32.7s\n",
      "1:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1.87s\tremaining: 4m 38s\n",
      "2:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 2.07s\tremaining: 3m 24s\n",
      "3:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 3s\tremaining: 3m 42s\n",
      "4:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5.29s\tremaining: 5m 11s\n",
      "5:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 8.32s\tremaining: 6m 47s\n",
      "6:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 9.57s\tremaining: 6m 40s\n",
      "7:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 13.5s\tremaining: 8m 10s\n",
      "8:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 13.6s\tremaining: 7m 18s\n",
      "9:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 17.4s\tremaining: 8m 23s\n",
      "10:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 18.7s\tremaining: 8m 11s\n",
      "11:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 21s\tremaining: 8m 23s\n",
      "12:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 21.9s\tremaining: 8m 4s\n",
      "13:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 25s\tremaining: 8m 31s\n",
      "14:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 25.4s\tremaining: 8m 2s\n",
      "15:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 25.9s\tremaining: 7m 39s\n",
      "16:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 28.2s\tremaining: 7m 49s\n",
      "17:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 28.5s\tremaining: 7m 27s\n",
      "18:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 33.5s\tremaining: 8m 16s\n",
      "19:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 40.3s\tremaining: 9m 24s\n",
      "20:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 40.5s\tremaining: 8m 57s\n",
      "21:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 45.8s\tremaining: 9m 38s\n",
      "22:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 48.5s\tremaining: 9m 43s\n",
      "23:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 59s\tremaining: 11m 18s\n",
      "24:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 59.1s\tremaining: 10m 49s\n",
      "25:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m\tremaining: 10m 35s\n",
      "26:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 4s\tremaining: 10m 54s\n",
      "27:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 6s\tremaining: 10m 46s\n",
      "28:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 9s\tremaining: 10m 49s\n",
      "29:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 9s\tremaining: 10m 27s\n",
      "30:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 10s\tremaining: 10m 14s\n",
      "31:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 11s\tremaining: 10m 2s\n",
      "32:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 13s\tremaining: 9m 52s\n",
      "33:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 13s\tremaining: 9m 34s\n",
      "34:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 14s\tremaining: 9m 24s\n",
      "35:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 16s\tremaining: 9m 19s\n",
      "36:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 17s\tremaining: 9m 7s\n",
      "37:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 22s\tremaining: 9m 25s\n",
      "38:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 26s\tremaining: 9m 36s\n",
      "39:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 29s\tremaining: 9m 38s\n",
      "40:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 29s\tremaining: 9m 23s\n",
      "41:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 29s\tremaining: 9m 8s\n",
      "42:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 30s\tremaining: 9m 2s\n",
      "43:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 33s\tremaining: 9m 2s\n",
      "44:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 35s\tremaining: 8m 58s\n",
      "45:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 35s\tremaining: 8m 46s\n",
      "46:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 36s\tremaining: 8m 38s\n",
      "47:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 38s\tremaining: 8m 39s\n",
      "48:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 39s\tremaining: 8m 29s\n",
      "49:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 41s\tremaining: 8m 27s\n",
      "50:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 42s\tremaining: 8m 22s\n",
      "51:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 43s\tremaining: 8m 11s\n",
      "52:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 45s\tremaining: 8m 11s\n",
      "53:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 51s\tremaining: 8m 26s\n",
      "54:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 51s\tremaining: 8m 16s\n",
      "55:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 52s\tremaining: 8m 10s\n",
      "56:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 54s\tremaining: 8m 9s\n",
      "57:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 55s\tremaining: 8m 3s\n",
      "58:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 1m 57s\tremaining: 8m 1s\n",
      "59:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 2m\tremaining: 8m 3s\n",
      "60:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 2m 1s\tremaining: 7m 57s\n",
      "61:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 2m 7s\tremaining: 8m 8s\n",
      "62:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 2m 15s\tremaining: 8m 28s\n",
      "63:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 2m 15s\tremaining: 8m 19s\n",
      "64:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 2m 19s\tremaining: 8m 23s\n",
      "65:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 2m 21s\tremaining: 8m 22s\n",
      "66:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 2m 24s\tremaining: 8m 22s\n",
      "67:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 2m 28s\tremaining: 8m 28s\n",
      "68:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 2m 32s\tremaining: 8m 29s\n",
      "69:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 2m 36s\tremaining: 8m 33s\n",
      "70:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 2m 41s\tremaining: 8m 39s\n",
      "71:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 2m 43s\tremaining: 8m 37s\n",
      "72:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 2m 45s\tremaining: 8m 34s\n",
      "73:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 2m 48s\tremaining: 8m 35s\n",
      "74:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 2m 57s\tremaining: 8m 51s\n",
      "75:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 3m 3s\tremaining: 9m 2s\n",
      "76:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 3m 4s\tremaining: 8m 54s\n",
      "77:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 3m 11s\tremaining: 9m 5s\n",
      "78:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 3m 11s\tremaining: 8m 56s\n",
      "79:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 3m 14s\tremaining: 8m 55s\n",
      "80:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 3m 18s\tremaining: 8m 55s\n",
      "81:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 3m 20s\tremaining: 8m 52s\n",
      "82:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 3m 25s\tremaining: 8m 56s\n",
      "83:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 3m 28s\tremaining: 8m 55s\n",
      "84:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 3m 32s\tremaining: 8m 58s\n",
      "85:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 3m 35s\tremaining: 8m 56s\n",
      "86:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 3m 40s\tremaining: 9m\n",
      "87:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 3m 49s\tremaining: 9m 12s\n",
      "88:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 3m 51s\tremaining: 9m 9s\n",
      "89:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 3m 57s\tremaining: 9m 14s\n",
      "90:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 3m 57s\tremaining: 9m 6s\n",
      "91:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 3m 58s\tremaining: 8m 58s\n",
      "92:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m\tremaining: 8m 56s\n",
      "93:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 1s\tremaining: 8m 48s\n",
      "94:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 2s\tremaining: 8m 42s\n",
      "95:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 7s\tremaining: 8m 46s\n",
      "96:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 13s\tremaining: 8m 50s\n",
      "97:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 17s\tremaining: 8m 51s\n",
      "98:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 22s\tremaining: 8m 52s\n",
      "99:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 22s\tremaining: 8m 44s\n",
      "100:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 23s\tremaining: 8m 39s\n",
      "101:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 27s\tremaining: 8m 39s\n",
      "102:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 33s\tremaining: 8m 42s\n",
      "103:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 33s\tremaining: 8m 35s\n",
      "104:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 34s\tremaining: 8m 30s\n",
      "105:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 34s\tremaining: 8m 23s\n",
      "106:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 39s\tremaining: 8m 24s\n",
      "107:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 43s\tremaining: 8m 24s\n",
      "108:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 47s\tremaining: 8m 22s\n",
      "109:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 47s\tremaining: 8m 16s\n",
      "110:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 47s\tremaining: 8m 9s\n",
      "111:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 51s\tremaining: 8m 8s\n",
      "112:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 55s\tremaining: 8m 8s\n",
      "113:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 58s\tremaining: 8m 6s\n",
      "114:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 4m 58s\tremaining: 8m\n",
      "115:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 2s\tremaining: 8m\n",
      "116:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 4s\tremaining: 7m 56s\n",
      "117:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 6s\tremaining: 7m 52s\n",
      "118:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 8s\tremaining: 7m 49s\n",
      "119:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 11s\tremaining: 7m 47s\n",
      "120:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 12s\tremaining: 7m 42s\n",
      "121:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 16s\tremaining: 7m 41s\n",
      "122:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 19s\tremaining: 7m 39s\n",
      "123:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 21s\tremaining: 7m 36s\n",
      "124:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 24s\tremaining: 7m 34s\n",
      "125:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 27s\tremaining: 7m 32s\n",
      "126:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 30s\tremaining: 7m 29s\n",
      "127:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 32s\tremaining: 7m 26s\n",
      "128:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 35s\tremaining: 7m 25s\n",
      "129:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 37s\tremaining: 7m 20s\n",
      "130:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 39s\tremaining: 7m 17s\n",
      "131:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 39s\tremaining: 7m 12s\n",
      "132:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 42s\tremaining: 7m 9s\n",
      "133:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 44s\tremaining: 7m 6s\n",
      "134:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 46s\tremaining: 7m 3s\n",
      "135:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 48s\tremaining: 7m\n",
      "136:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 52s\tremaining: 6m 59s\n",
      "137:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 56s\tremaining: 6m 58s\n",
      "138:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 5m 57s\tremaining: 6m 53s\n",
      "139:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m\tremaining: 6m 51s\n",
      "140:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 3s\tremaining: 6m 50s\n",
      "141:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 4s\tremaining: 6m 45s\n",
      "142:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 9s\tremaining: 6m 45s\n",
      "143:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 11s\tremaining: 6m 42s\n",
      "144:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 13s\tremaining: 6m 39s\n",
      "145:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 16s\tremaining: 6m 36s\n",
      "146:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 18s\tremaining: 6m 34s\n",
      "147:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 21s\tremaining: 6m 31s\n",
      "148:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 27s\tremaining: 6m 32s\n",
      "149:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 30s\tremaining: 6m 30s\n",
      "150:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 33s\tremaining: 6m 28s\n",
      "151:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 36s\tremaining: 6m 26s\n",
      "152:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 38s\tremaining: 6m 23s\n",
      "153:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 39s\tremaining: 6m 18s\n",
      "154:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 40s\tremaining: 6m 14s\n",
      "155:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 43s\tremaining: 6m 12s\n",
      "156:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 46s\tremaining: 6m 10s\n",
      "157:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 46s\tremaining: 6m 5s\n",
      "158:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 47s\tremaining: 6m 1s\n",
      "159:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 48s\tremaining: 5m 57s\n",
      "160:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 49s\tremaining: 5m 53s\n",
      "161:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 50s\tremaining: 5m 49s\n",
      "162:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 53s\tremaining: 5m 47s\n",
      "163:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 54s\tremaining: 5m 43s\n",
      "164:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 55s\tremaining: 5m 39s\n",
      "165:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 55s\tremaining: 5m 35s\n",
      "166:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 56s\tremaining: 5m 31s\n",
      "167:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 58s\tremaining: 5m 28s\n",
      "168:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 58s\tremaining: 5m 24s\n",
      "169:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 58s\tremaining: 5m 20s\n",
      "170:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 59s\tremaining: 5m 16s\n",
      "171:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 6m 59s\tremaining: 5m 12s\n",
      "172:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m\tremaining: 5m 8s\n",
      "173:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 1s\tremaining: 5m 5s\n",
      "174:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 1s\tremaining: 5m 1s\n",
      "175:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 2s\tremaining: 4m 57s\n",
      "176:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 3s\tremaining: 4m 54s\n",
      "177:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 4s\tremaining: 4m 50s\n",
      "178:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 5s\tremaining: 4m 47s\n",
      "179:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 7s\tremaining: 4m 44s\n",
      "180:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 8s\tremaining: 4m 41s\n",
      "181:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 8s\tremaining: 4m 38s\n",
      "182:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 9s\tremaining: 4m 34s\n",
      "183:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 9s\tremaining: 4m 31s\n",
      "184:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 10s\tremaining: 4m 27s\n",
      "185:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 10s\tremaining: 4m 24s\n",
      "186:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 11s\tremaining: 4m 20s\n",
      "187:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 12s\tremaining: 4m 17s\n",
      "188:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 13s\tremaining: 4m 14s\n",
      "189:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 13s\tremaining: 4m 11s\n",
      "190:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 15s\tremaining: 4m 8s\n",
      "191:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 16s\tremaining: 4m 5s\n",
      "192:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 18s\tremaining: 4m 2s\n",
      "193:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 18s\tremaining: 3m 59s\n",
      "194:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 19s\tremaining: 3m 56s\n",
      "195:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 23s\tremaining: 3m 55s\n",
      "196:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 24s\tremaining: 3m 52s\n",
      "197:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 25s\tremaining: 3m 49s\n",
      "198:\tlearn: 0.0000000\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 27s\tremaining: 3m 47s\n",
      "199:\tlearn: 0.0038911\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 29s\tremaining: 3m 44s\n",
      "200:\tlearn: 0.0038911\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 30s\tremaining: 3m 42s\n",
      "201:\tlearn: 0.0038911\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 32s\tremaining: 3m 39s\n",
      "202:\tlearn: 0.0038911\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 35s\tremaining: 3m 37s\n",
      "203:\tlearn: 0.0038911\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 37s\tremaining: 3m 35s\n",
      "204:\tlearn: 0.0077821\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 40s\tremaining: 3m 33s\n",
      "205:\tlearn: 0.0077821\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 41s\tremaining: 3m 30s\n",
      "206:\tlearn: 0.0077821\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 43s\tremaining: 3m 28s\n",
      "207:\tlearn: 0.0077821\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 45s\tremaining: 3m 25s\n",
      "208:\tlearn: 0.0077821\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 47s\tremaining: 3m 23s\n",
      "209:\tlearn: 0.0077821\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 49s\tremaining: 3m 21s\n",
      "210:\tlearn: 0.0116732\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 53s\tremaining: 3m 19s\n",
      "211:\tlearn: 0.0116732\ttest: 0.0000000\tbest: 0.0000000 (0)\ttotal: 7m 55s\tremaining: 3m 17s\n",
      "212:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 7m 56s\tremaining: 3m 14s\n",
      "213:\tlearn: 0.0194553\ttest: 0.0000000\tbest: 0.0156250 (212)\ttotal: 7m 56s\tremaining: 3m 11s\n",
      "214:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 7m 57s\tremaining: 3m 8s\n",
      "215:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 7m 57s\tremaining: 3m 5s\n",
      "216:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 7m 58s\tremaining: 3m 3s\n",
      "217:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 7m 59s\tremaining: 3m\n",
      "218:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m\tremaining: 2m 57s\n",
      "219:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m\tremaining: 2m 54s\n",
      "220:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 1s\tremaining: 2m 52s\n",
      "221:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 2s\tremaining: 2m 49s\n",
      "222:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 3s\tremaining: 2m 46s\n",
      "223:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 4s\tremaining: 2m 44s\n",
      "224:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 5s\tremaining: 2m 41s\n",
      "225:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 6s\tremaining: 2m 39s\n",
      "226:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 6s\tremaining: 2m 36s\n",
      "227:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 6s\tremaining: 2m 33s\n",
      "228:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 7s\tremaining: 2m 31s\n",
      "229:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 8s\tremaining: 2m 28s\n",
      "230:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 8s\tremaining: 2m 25s\n",
      "231:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 9s\tremaining: 2m 23s\n",
      "232:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 10s\tremaining: 2m 20s\n",
      "233:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 11s\tremaining: 2m 18s\n",
      "234:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 11s\tremaining: 2m 16s\n",
      "235:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 12s\tremaining: 2m 13s\n",
      "236:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 13s\tremaining: 2m 11s\n",
      "237:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 14s\tremaining: 2m 8s\n",
      "238:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 15s\tremaining: 2m 6s\n",
      "239:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 16s\tremaining: 2m 4s\n",
      "240:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 17s\tremaining: 2m 1s\n",
      "241:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 17s\tremaining: 1m 59s\n",
      "242:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 18s\tremaining: 1m 56s\n",
      "243:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 19s\tremaining: 1m 54s\n",
      "244:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 23s\tremaining: 1m 52s\n",
      "245:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 24s\tremaining: 1m 50s\n",
      "246:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 25s\tremaining: 1m 48s\n",
      "247:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 25s\tremaining: 1m 46s\n",
      "248:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 26s\tremaining: 1m 43s\n",
      "249:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 26s\tremaining: 1m 41s\n",
      "250:\tlearn: 0.0194553\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 27s\tremaining: 1m 38s\n",
      "251:\tlearn: 0.0233463\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 27s\tremaining: 1m 36s\n",
      "252:\tlearn: 0.0233463\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 28s\tremaining: 1m 34s\n",
      "253:\tlearn: 0.0233463\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 28s\tremaining: 1m 32s\n",
      "254:\tlearn: 0.0233463\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 29s\tremaining: 1m 29s\n",
      "255:\tlearn: 0.0233463\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 30s\tremaining: 1m 27s\n",
      "256:\tlearn: 0.0233463\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 30s\tremaining: 1m 25s\n",
      "257:\tlearn: 0.0233463\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 31s\tremaining: 1m 23s\n",
      "258:\tlearn: 0.0233463\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 32s\tremaining: 1m 21s\n",
      "259:\tlearn: 0.0233463\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 33s\tremaining: 1m 18s\n",
      "260:\tlearn: 0.0233463\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 34s\tremaining: 1m 16s\n",
      "261:\tlearn: 0.0233463\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 36s\tremaining: 1m 14s\n",
      "262:\tlearn: 0.0233463\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 37s\tremaining: 1m 12s\n",
      "263:\tlearn: 0.0272374\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 38s\tremaining: 1m 10s\n",
      "264:\tlearn: 0.0272374\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 39s\tremaining: 1m 8s\n",
      "265:\tlearn: 0.0272374\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 40s\tremaining: 1m 6s\n",
      "266:\tlearn: 0.0272374\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 42s\tremaining: 1m 4s\n",
      "267:\tlearn: 0.0272374\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 42s\tremaining: 1m 2s\n",
      "268:\tlearn: 0.0272374\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 44s\tremaining: 1m\n",
      "269:\tlearn: 0.0272374\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 46s\tremaining: 58.4s\n",
      "270:\tlearn: 0.0272374\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 46s\tremaining: 56.3s\n",
      "271:\tlearn: 0.0311284\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 46s\tremaining: 54.2s\n",
      "272:\tlearn: 0.0311284\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 48s\tremaining: 52.2s\n",
      "273:\tlearn: 0.0311284\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 48s\tremaining: 50.1s\n",
      "274:\tlearn: 0.0311284\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 49s\tremaining: 48.1s\n",
      "275:\tlearn: 0.0350195\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 51s\tremaining: 46.2s\n",
      "276:\tlearn: 0.0350195\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 53s\tremaining: 44.3s\n",
      "277:\tlearn: 0.0350195\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 53s\tremaining: 42.2s\n",
      "278:\tlearn: 0.0350195\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 54s\tremaining: 40.2s\n",
      "279:\tlearn: 0.0350195\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 54s\tremaining: 38.2s\n",
      "280:\tlearn: 0.0350195\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 55s\tremaining: 36.2s\n",
      "281:\tlearn: 0.0350195\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 55s\tremaining: 34.2s\n",
      "282:\tlearn: 0.0350195\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 55s\tremaining: 32.2s\n",
      "283:\tlearn: 0.0350195\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 55s\tremaining: 30.2s\n",
      "284:\tlearn: 0.0350195\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 56s\tremaining: 28.2s\n",
      "285:\tlearn: 0.0350195\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 56s\tremaining: 26.3s\n",
      "286:\tlearn: 0.0350195\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 56s\tremaining: 24.3s\n",
      "287:\tlearn: 0.0350195\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 57s\tremaining: 22.4s\n",
      "288:\tlearn: 0.0350195\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 57s\tremaining: 20.5s\n",
      "289:\tlearn: 0.0350195\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 57s\tremaining: 18.5s\n",
      "290:\tlearn: 0.0350195\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 57s\tremaining: 16.6s\n",
      "291:\tlearn: 0.0389105\ttest: 0.0156250\tbest: 0.0156250 (212)\ttotal: 8m 58s\tremaining: 14.7s\n",
      "292:\tlearn: 0.0389105\ttest: 0.0312500\tbest: 0.0312500 (292)\ttotal: 8m 58s\tremaining: 12.9s\n",
      "293:\tlearn: 0.0389105\ttest: 0.0312500\tbest: 0.0312500 (292)\ttotal: 8m 58s\tremaining: 11s\n",
      "294:\tlearn: 0.0389105\ttest: 0.0312500\tbest: 0.0312500 (292)\ttotal: 8m 59s\tremaining: 9.14s\n",
      "295:\tlearn: 0.0389105\ttest: 0.0312500\tbest: 0.0312500 (292)\ttotal: 8m 59s\tremaining: 7.29s\n",
      "296:\tlearn: 0.0389105\ttest: 0.0312500\tbest: 0.0312500 (292)\ttotal: 8m 59s\tremaining: 5.45s\n",
      "297:\tlearn: 0.0428016\ttest: 0.0312500\tbest: 0.0312500 (292)\ttotal: 9m 1s\tremaining: 3.64s\n",
      "298:\tlearn: 0.0428016\ttest: 0.0312500\tbest: 0.0312500 (292)\ttotal: 9m 2s\tremaining: 1.81s\n",
      "299:\tlearn: 0.0428016\ttest: 0.0312500\tbest: 0.0312500 (292)\ttotal: 9m 3s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.03125\n",
      "bestIteration = 292\n",
      "\n",
      "Shrink model to first 293 iterations.\n",
      "Accuracy:  0.942\n",
      "Precision: 0.942\n",
      "Recall:    1.000\n",
      "\n",
      "Full classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     granted       0.94      1.00      0.97      1004\n",
      "     refused       1.00      0.03      0.06        64\n",
      "\n",
      "    accuracy                           0.94      1068\n",
      "   macro avg       0.97      0.52      0.52      1068\n",
      "weighted avg       0.95      0.94      0.92      1068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "missing_cat_placeholder = 'nan'\n",
    "\n",
    "for c in cat_cols:\n",
    "    X[c] = X[c].astype(str).fillna(missing_cat_placeholder)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "train_pool = Pool(data=X_train, label=y_train, cat_features=cat_cols)\n",
    "test_pool = Pool(data=X_test, label=y_test, cat_features=cat_cols)\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "        iterations=300,\n",
    "        learning_rate=0.01,\n",
    "        depth=6,\n",
    "        eval_metric='Recall',\n",
    "        random_seed=42,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "# Fit the model\n",
    "model.fit(train_pool, eval_set=test_pool)\n",
    "    \n",
    "# Predictions\n",
    "y_pred = model.predict(test_pool)\n",
    "y_pred_prob = model.predict_proba(test_pool)\n",
    "\n",
    "    \n",
    "# Compute metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, pos_label='granted', zero_division=0)\n",
    "rec = recall_score(y_test, y_pred, pos_label='granted', zero_division=0)\n",
    "    \n",
    "print(f\"Accuracy:  {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall:    {rec:.3f}\")\n",
    "print(\"\\nFull classification report:\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1068"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1068"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame()\n",
    "df_pred['preds'] = y_pred\n",
    "df_pred['preds_prob1'] = y_pred_prob[:,1]\n",
    "df_pred['preds_prob0'] = y_pred_prob[:,0]\n",
    "\n",
    "\n",
    "df_pred['gt_values'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gt_values\n",
       "granted    1004\n",
       "refused      64\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.gt_values.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refused 0.33615405174251867\n",
      "Granted 0.6638459482574813\n"
     ]
    }
   ],
   "source": [
    "print('Refused',df_pred[df_pred.gt_values=='refused'].preds_prob1.median())\n",
    "print('Granted',df_pred[df_pred.gt_values=='refused'].preds_prob0.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refused 0.03755523798849743\n",
      "Granted 0.9624447620115025\n"
     ]
    }
   ],
   "source": [
    "print('Refused',df_pred[df_pred.gt_values=='granted'].preds_prob1.median())\n",
    "print('Granted',df_pred[df_pred.gt_values=='granted'].preds_prob0.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_truc = np.where(y_pred_prob[:,1] > 0.3, 'refused', 'granted')\n",
    "#pred_truc = np.where(y_pred_prob[:,0] > 0.9, 'granted', 'refused')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.958\n",
      "Precision: 0.971\n",
      "Recall:    0.984\n",
      "\n",
      "Full classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     granted       0.97      0.98      0.98      1004\n",
      "     refused       0.69      0.55      0.61        64\n",
      "\n",
      "    accuracy                           0.96      1068\n",
      "   macro avg       0.83      0.77      0.79      1068\n",
      "weighted avg       0.95      0.96      0.96      1068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, pred_truc)\n",
    "prec = precision_score(y_test, pred_truc, pos_label='granted', zero_division=0)\n",
    "rec = recall_score(y_test, pred_truc, pos_label='granted', zero_division=0)\n",
    "    \n",
    "print(f\"Accuracy:  {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall:    {rec:.3f}\")\n",
    "print(\"\\nFull classification report:\\n\")\n",
    "print(classification_report(y_test, pred_truc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['granted', 'refused']  # adjust order if needed\n",
    "\n",
    "# 1) compute raw matrix\n",
    "cm = confusion_matrix(y_test, pred_truc, labels=labels)\n",
    "\n",
    "# 2) wrap in a DataFrame for clarity\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[f\"actual_{lab}\"   for lab in labels],\n",
    "    columns=[f\"predicted_{lab}\" for lab in labels]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_granted</th>\n",
       "      <th>predicted_refused</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_granted</th>\n",
       "      <td>988</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_refused</th>\n",
       "      <td>29</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predicted_granted  predicted_refused\n",
       "actual_granted                988                 16\n",
       "actual_refused                 29                 35"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/albafranco/Documents/Python/visa-scoring/notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/albafranco/Documents/Python/visa-scoring\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_training import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_columns_with_mixed_dtypes(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Prints columns in the DataFrame that contain mixed data types (e.g., strings and numbers).\n",
    "    \"\"\"\n",
    "    mixed_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        types_in_col = set(type(val) for val in df[col].dropna())\n",
    "        if len(types_in_col) > 1:\n",
    "            mixed_cols.append((col, types_in_col))\n",
    "\n",
    "    if mixed_cols:\n",
    "        print(\"Columns with mixed data types:\")\n",
    "        for col, types_found in mixed_cols:\n",
    "            print(f\"  - {col}: {types_found}\")\n",
    "    else:\n",
    "        print(\"No columns with mixed data types found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with mixed data types:\n",
      "  - postal_code_cd_raiucor: {<class 'str'>, <class 'float'>}\n",
      "  - business_phone_cd_ctniucor: {<class 'str'>, <class 'float'>}\n",
      "  - home_phone_cd_ctniucor: {<class 'str'>, <class 'float'>}\n"
     ]
    }
   ],
   "source": [
    "print_columns_with_mixed_dtypes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "postal_code = [i for i in df.columns if 'postal' in i]\n",
    "mobile_phone = [i for i in df.columns if 'phone' in i]\n",
    "df = df.drop(columns = postal_code + mobile_phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No columns with mixed data types found.\n"
     ]
    }
   ],
   "source": [
    "print_columns_with_mixed_dtypes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5340, 522)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Preparing data...\n",
      "INFO:root:Encoding categorical columns with OrdinalEncoder for XGBoost...\n",
      "INFO:root:Splitting data into train/test sets...\n",
      "INFO:root:Training XGBoostClassifier...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1], got ['granted' 'refused']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model_xgb, df_pred_xgb = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mxgboost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                                     \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtype_case\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Python/visa-scoring/src/model_training.py:77\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(df, model_type, target_col, threshold)\u001b[39m\n\u001b[32m     68\u001b[39m logging.info(\u001b[33m\"\u001b[39m\u001b[33mTraining XGBoostClassifier...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     69\u001b[39m model = XGBClassifier(\n\u001b[32m     70\u001b[39m     n_estimators=\u001b[32m300\u001b[39m,\n\u001b[32m     71\u001b[39m     learning_rate=\u001b[32m0.01\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     75\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m y_pred = model.predict(X_test)\n\u001b[32m     79\u001b[39m y_pred_prob = model.predict_proba(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/sklearn.py:1640\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1635\u001b[39m     expected_classes = \u001b[38;5;28mself\u001b[39m.classes_\n\u001b[32m   1636\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1637\u001b[39m     classes.shape != expected_classes.shape\n\u001b[32m   1638\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes == expected_classes).all()\n\u001b[32m   1639\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1640\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1641\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1642\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1643\u001b[39m     )\n\u001b[32m   1645\u001b[39m params = \u001b[38;5;28mself\u001b[39m.get_xgb_params()\n\u001b[32m   1647\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n",
      "\u001b[31mValueError\u001b[39m: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got ['granted' 'refused']"
     ]
    }
   ],
   "source": [
    "model_xgb, df_pred_xgb = train_model(df, model_type ='xgboost',\n",
    "                                     target_col='type_case', threshold=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
