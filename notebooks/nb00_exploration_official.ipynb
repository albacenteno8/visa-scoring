{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdfplumber\n",
    "import re\n",
    "import glob\n",
    "import unicodedata\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slugify(text: str) -> str:\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    text = ''.join(c for c in text if not unicodedata.combining(c))\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9]+', '_', text)\n",
    "    return re.sub(r'_+', '_', text).strip('_')\n",
    "\n",
    "def normalize_question(q: str) -> str:\n",
    "    \"\"\"\n",
    "    Normaliza preguntas que varían por contenidos entre paréntesis u otras variables,\n",
    "    reemplazando patrones específicos por una versión genérica.\n",
    "    \"\"\"\n",
    "    # Patrón para la pregunta de ciudadanía con country variable\n",
    "    citizen_pat = re.compile(\n",
    "        r\"^Is this applicant a citizen of the selected country of passport.*\\?$\", \n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    if citizen_pat.match(q):\n",
    "        return \"Is this applicant a citizen of the selected country of passport?\"\n",
    "    # Añade otros patrones de normalización aquí si es necesario\n",
    "    return q\n",
    "\n",
    "def extract_questions_answers(pdf_path: str) -> list:\n",
    "    \"\"\"\n",
    "    Extrae lista de (pregunta_normalizada, respuesta) del PDF,\n",
    "    uniendo fragmentos multi‑línea y saltándose secciones y campos inline.\n",
    "    \"\"\"\n",
    "    section_re = re.compile(r'^[A-Z][A-Za-z ]+$')\n",
    "    inline_re  = re.compile(r'^(.+?):')\n",
    "    \n",
    "    # 1) Leer todas las líneas\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        lines = []\n",
    "        for p in pdf.pages:\n",
    "            lines.extend((p.extract_text() or '').split('\\n'))\n",
    "    lines = [l.strip() for l in lines if l.strip()]\n",
    "    \n",
    "    qa = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        # 2) Detectar fin de pregunta\n",
    "        if lines[i].endswith('?'):\n",
    "            # 3) Retroceder para juntar cualquier fragmento previo\n",
    "            j = i - 1\n",
    "            question_fragments = [lines[i]]\n",
    "            while j >= 0:\n",
    "                prev = lines[j]\n",
    "                # si es inline o sección o termina en '?' dejamos de retroceder\n",
    "                if inline_re.match(prev) or section_re.match(prev) or prev.endswith('?'):\n",
    "                    break\n",
    "                # si no, es parte de la pregunta -> insertarlo al inicio\n",
    "                question_fragments.insert(0, prev)\n",
    "                j -= 1\n",
    "            \n",
    "            full_q = \" \".join(question_fragments)\n",
    "            # 4) Buscar la respuesta (primera línea no‑pregunta tras el '?')\n",
    "            k = i + 1\n",
    "            while k < len(lines) and lines[k].endswith('?'):\n",
    "                k += 1\n",
    "            answer = lines[k] if k < len(lines) else \"\"\n",
    "            \n",
    "            # 5) Normalizar y guardar\n",
    "            norm_q = normalize_question(full_q)\n",
    "            qa.append((norm_q, answer))\n",
    "            \n",
    "            # 6) Saltar past la respuesta\n",
    "            i = k + 1\n",
    "            continue\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    return qa\n",
    "\n",
    "def extract_fields_with_context(pdf_path: str) -> dict:\n",
    "    data = {}\n",
    "    current_section = None\n",
    "    section_pattern = re.compile(r'^[A-Z][A-Za-z ]+$')\n",
    "    inline_pattern  = re.compile(r'^(.+?):\\s*(.+)$')\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            for line in page.extract_text().split('\\n'):\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                if section_pattern.match(line) and ':' not in line and not line.endswith('?'):\n",
    "                    current_section = slugify(line)\n",
    "                    continue\n",
    "                m = inline_pattern.match(line)\n",
    "                if m:\n",
    "                    field, val = m.groups()\n",
    "                    key = slugify(field)\n",
    "                    if current_section:\n",
    "                        key = f\"{current_section}_{key}\"\n",
    "                    data[key] = val.strip()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_application_pdfs(root_folder: str, question_map=None):\n",
    "    \"\"\"\n",
    "    Procesa subcarpetas numeradas en root_folder.\n",
    "    - question_map: dict existente {idx: pregunta}. Si es None, se inicia vacío.\n",
    "    Devuelve (DataFrame, updated_question_map).\n",
    "    \"\"\"\n",
    "    if question_map is None:\n",
    "        question_map = {}\n",
    "    rows = []\n",
    "\n",
    "    items_list = [d for d in set(os.listdir(root_folder)) if d != '.DS_Store']\n",
    "\n",
    "    for sample_dir in tqdm(sorted(items_list, key=lambda x: int(x) if x.isdigit() else x)):\n",
    "        folder = os.path.join(root_folder, sample_dir)\n",
    "        if not os.path.isdir(folder): continue\n",
    "        # renombrar archivos a minúsculas\n",
    "        for fname in os.listdir(folder):\n",
    "            old, new = os.path.join(folder,fname), os.path.join(folder,fname.lower())\n",
    "            if old != new: os.rename(old,new)\n",
    "        # buscar PDF\n",
    "        cands = [f for f in os.listdir(folder) if 'application' in f and f.endswith('.pdf')]\n",
    "        if not cands: continue\n",
    "        pdf_path = os.path.join(folder, cands[0])\n",
    "        inline_data = extract_fields_with_context(pdf_path)\n",
    "        qa_list = extract_questions_answers(pdf_path)\n",
    "        # actualizar mapping\n",
    "        for q, _ in qa_list:\n",
    "            if q not in question_map.values():\n",
    "                new_idx = max(question_map.keys(), default=0) + 1\n",
    "                question_map[new_idx] = q\n",
    "        # construir fila\n",
    "        row = dict(inline_data)\n",
    "        row['sample_id'] = sample_dir\n",
    "        row['source_file'] = os.path.basename(pdf_path)\n",
    "        # inicializar columnas de respuestas\n",
    "        for idx in question_map:\n",
    "            row[f'question_{idx}'] = None\n",
    "        # asignar respuestas\n",
    "        for idx, q_text in question_map.items():\n",
    "            for q, a in qa_list:\n",
    "                if q == q_text:\n",
    "                    row[f'question_{idx}'] = a\n",
    "                    break\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df, question_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta raíz donde están las carpetas numeradas\n",
    "\n",
    "df_all_granted, question_map_g = process_application_pdfs('data/granted/')\n",
    "df_all_granted['final_visa_status'] = 'granted'\n",
    "\n",
    "print(len(question_map_g))\n",
    "\n",
    "df_all_refused, question_map_r = process_application_pdfs('data/refused/', question_map = question_map_g)\n",
    "df_all_refused['final_visa_status'] = 'refused'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(question_map_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_map_r[69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_refused.shape#[['question_69','question_70','question_80','question_81']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_all_granted,df_all_refused])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
